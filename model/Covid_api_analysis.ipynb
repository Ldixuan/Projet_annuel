{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covid_api_analysis.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gOYVdxSrBbm"
      },
      "source": [
        "!pip install fbprophet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI6DFVhzrP7o"
      },
      "source": [
        "! pip install covid-data-api\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5kIxp2WrnVb"
      },
      "source": [
        "#Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm5B4zB2rKrn"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.python.keras.models import load_model\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from fbprophet import Prophet\n",
        "from fbprophet.plot import plot_plotly, add_changepoints_to_plot\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFJbv3Dtr-SU"
      },
      "source": [
        "#Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulMbnxhksAOH"
      },
      "source": [
        "look_back=10\n",
        "def creation_dataset_train_test(trainX, look_back,testX):\n",
        "    trainX, trainY = create_dataset(trainX, look_back)\n",
        "    testX, testY = create_dataset(testX, look_back)\n",
        "    trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
        "    testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
        "    return trainX,testX, testY,testY\n",
        "\n",
        "def scaling(y_deaths):\n",
        "      # normalize the dataset\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    y_deaths= scaler.fit_transform(y_deaths.reshape(-1,1))\n",
        "    return y_deaths, scaler\n",
        "def create_dataset(dataset, look_back):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back)]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + look_back])\n",
        "    return np.array(dataX), np.array(dataY)\n",
        "\n",
        "\n",
        "\n",
        "def split_train_test(y_deaths):\n",
        "    train_size = int(len(y_deaths) * 0.9)\n",
        "\n",
        "    test_size = len(y_deaths) - train_size\n",
        "    print(\"test_size\", test_size)\n",
        "    X=[]\n",
        "    for i in range(len(y_deaths)):\n",
        "       X.append(i)\n",
        "    trainX,testX,trainY,testY=X[0:train_size],X[train_size:],y_deaths[0:train_size],y_deaths[-train_size:]\n",
        "    print(\"len trzin , test \",len(trainX), len(testX))\n",
        "    return trainX,testX,trainY,testY\n",
        "\n",
        "import tensorflow as tf \n",
        "def train_eval_model_keras(norm,  df, nb_epochs, batch_size):\n",
        "    y_deaths=df.values\n",
        "    \n",
        "    if (norm):\n",
        "         y_deaths, scaler = scaling(df.values)\n",
        "    trainX,testX,trainY,testY=split_train_test(y_deaths)\n",
        "    trainX,testX, testY,testY = creation_dataset_train_test(trainX, look_back,testX)\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(20, input_shape=(look_back, 1)))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    history=model.fit(trainX, trainY, epochs=nb_epochs, batch_size=batch_size , validation_split=0.2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()\n",
        "    score = model.evaluate(testX, testY, verbose=0)\n",
        "    print( \"Score d'evaluation\", score )\n",
        "    df=pd.DataFrame(columns =  ['yhat','y'])\n",
        "    if (norm):\n",
        "      \n",
        "      df[\"y\"]=scaler.inverse_transform(testY.reshape(-1,1)).reshape(-1)\n",
        "      df[\"yhat\"]=  scaler.inverse_transform(model.predict(testX).reshape(-1,1)).reshape(-1)\n",
        "      #print(\"prediction data\" ,df[\"yhat\"].value_counts())\n",
        "      #print( \"df /n\",df)\n",
        "    else: \n",
        "      df[\"y\"]=testY\n",
        "      df[\"yhat\"]=  model.predict(testX)\n",
        "      #print(\" prediction data\" ,df[\"yhat\"].value_counts())\n",
        "      #print( \"df /n\",df)\n",
        "    return df \n",
        "\n",
        "\n",
        "def fb_prophet_prediction(df):\n",
        "    nb_future_day=60\n",
        "    fb_df=pd.DataFrame(columns =  ['ds','y'])\n",
        "\n",
        "    fb_df['ds']=df.index[:-nb_future_day]\n",
        "    fb_df['y']=df.values[:-nb_future_day]\n",
        "    \n",
        "    test=fb_df.values[-nb_future_day:]\n",
        "    from fbprophet import Prophet\n",
        "    model = Prophet(interval_width =0.95)\n",
        "    model.fit(fb_df)\n",
        "    future  = model.make_future_dataframe(periods=nb_future_day)\n",
        "    forecast_df= model.predict(future)\n",
        "    forecast_df[\"true\"]=df.values\n",
        "    forecast_df=forecast_df[['ds','true','yhat','yhat_lower','yhat_upper']][-nb_future_day:]\n",
        "    \n",
        "    # Python\n",
        "    fig1 = model.plot(forecast_df)\n",
        "    return forecast_df\n",
        "\n",
        "\n",
        "def get_prediction_using_ARIMA(df , colone):\n",
        "        nb_days=60\n",
        "        df_values = df.values[:-nb_days]\n",
        "        data = pd.DataFrame(columns = ['ds','y'])\n",
        "        data['ds']  = df.index[:-nb_days]\n",
        "        data['y'] = df_values \n",
        "        arima = ARIMA(data['y'], order=(5, 1, 0))\n",
        "        arima = arima.fit(trend='c', full_output=True, disp=True)\n",
        "        forecast = arima.forecast(steps= nb_days)\n",
        "        pred = list(forecast[0])\n",
        "        prediction_dates= df.index[-nb_days:]\n",
        "        print(len(pred), len(prediction_dates))\n",
        "        print(df.index)\n",
        "        \n",
        "        df_arima= pd.DataFrame(columns = ['y_predicted','y_true'])\n",
        "        df_arima['y_predicted']=pred\n",
        "        df_arima['y_true']=df.values[-nb_days:]\n",
        "\n",
        "        plt.figure(figsize= (15,10))\n",
        "        plt.xlabel(\"Dates\",fontsize = 20)\n",
        "        plt.ylabel('Total cases',fontsize = 20)\n",
        "        title= \"ARIMA model : Predicted Values for \" + str(colone)+ \" for \"+ str(nb_days) + \" Days  \"\n",
        "        plt.title(title , fontsize = 20)\n",
        "\n",
        "        plt.plot_date(y= pred,x= prediction_dates,linestyle ='dashed',color = '#ff9999',label = 'Predicted');\n",
        "        print( prediction_dates)\n",
        "        print(df.index)\n",
        "        #plt.plot_date(y=data['y'],x=data['ds'],linestyle = '-',color = 'blue',label = 'Actual');\n",
        "        plt.plot_date(y=df.values,x=df.index,linestyle = '-',color = 'green',label = 'Actual');\n",
        "        plt.legend()\n",
        "        return df_arima"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZeF9BuMr0py"
      },
      "source": [
        "# Extarction data from API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiX9SL7gry3g"
      },
      "source": [
        "from covid.api import CovId19Data\n",
        "\n",
        "api = CovId19Data(force=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCD5p4e5r8Ss"
      },
      "source": [
        "import pandas as pd\n",
        "from covid.api import CovId19Data\n",
        "import re\n",
        "\n",
        "class Extraction_data:\n",
        "    def __init__(self,country_name, api):\n",
        "        self.country_name=country_name\n",
        "        self.api=api\n",
        "\n",
        "    def data_extraction_from_api(self):\n",
        "\n",
        "        data_from_api = self.api.get_history_by_country(self.country_name)\n",
        "\n",
        "        # Getting dictionary\n",
        "        data_dict = data_from_api  # json.dumps(data_from_api)\n",
        "        return data_dict\n",
        "    def data_preprocessing(self, data_dict):\n",
        "        #data_preporcessing\n",
        "        country_name = re.sub('[()\\'\\-,;]', '', self.country_name.lower())\n",
        "        if (\" \" in country_name):\n",
        "            country_name = \"_\".join(re.split(\" \", country_name.lower()))\n",
        "\n",
        "        # creating géo dictionary : optional\n",
        "        \"\"\"geo_data=dict()\n",
        "        geo_data[\"country\"]=data_dict[country_name][\"label\"] \n",
        "        geo_data[\"lat\"]=data_dict[country_name][\"lat\"] \n",
        "        geo_data[\"long\"]=data_dict[country_name][\"long\"] \n",
        "        print( \"géo dictionary\" ,geo_data)\"\"\"\n",
        "\n",
        "        # getting historical data\n",
        "        historical_data = data_dict[country_name][\"history\"]\n",
        "        data_frame = pd.DataFrame.from_dict(historical_data, orient='index')\n",
        "        return data_frame[[\"confirmed\", \"deaths\", \"recovered\"]]\n",
        "\n",
        "    def save_data_to_csv(self, data_frame):\n",
        "        # save to csv\n",
        "        filename = \"data_\" + self.country_name + \".csv\"\n",
        "        data_frame.to_csv(filename)\n",
        "\n",
        "\n",
        "    def run(self):\n",
        "        data_dict= self.data_extraction_from_api()\n",
        "        data_frame=self.data_preprocessing( data_dict)\n",
        "        self.save_data_to_csv(data_frame)\n",
        "        return data_frame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjPXcvvhs2P6"
      },
      "source": [
        "# France Covid analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmv4lr0Cs1oD"
      },
      "source": [
        "france_data= Extraction_data(\"France\", api).run()\n",
        "print(france_data[\"confirmed\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lvKj4Z3t9lm"
      },
      "source": [
        " ## Prediction for Confirmed cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yashHhyruAnW"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5O-QZsgs09k"
      },
      "source": [
        "df = train_eval_model_keras(norm=True, df=france_data[\"confirmed\"], nb_epochs=30, batch_size=10)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wkxe8hTexSMS"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=df.index, y=df[\"y\"],\n",
        "                    mode='lines+markers',\n",
        "                    name='confirmed',marker_color='purple'))\n",
        "fig.add_trace(go.Scatter(x=df.index, y=df[\"yhat\"],\n",
        "                    mode='lines+markers',\n",
        "                    name='confirmed_prediction', marker_color='green'))\n",
        "\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0V4ggI2yuJx"
      },
      "source": [
        "#calcule mse , \n",
        "\n",
        "mae = metrics.mean_absolute_error(df[\"y\"], df[\"yhat\"])\n",
        "mse = metrics.mean_squared_error(df[\"y\"], df[\"yhat\"])\n",
        "rmse = np.sqrt(mse) # or mse**(0.5)  \n",
        "r2 = metrics.r2_score(df[\"y\"], df[\"yhat\"])\n",
        "\n",
        "print(\"Results of sklearn.metrics:\")\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MSE:\", mse)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R-Squared:\", r2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vria_81QuRLg"
      },
      "source": [
        "##Arima"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLiMYjsyysyD"
      },
      "source": [
        "df_arima =get_prediction_using_ARIMA(france_data[\"confirmed\"], \"confirmed cases\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoSrRy-6uWVt"
      },
      "source": [
        "mae = metrics.mean_absolute_error(df_arima[\"y_true\"], df_arima[\"y_predicted\"])\n",
        "mse = metrics.mean_squared_error(df_arima[\"y_true\"], df_arima[\"y_predicted\"])\n",
        "rmse = np.sqrt(mse) # or mse**(0.5)  \n",
        "r2 = metrics.r2_score(df_arima[\"y_true\"], df_arima[\"y_predicted\"])\n",
        "\n",
        "print(\"Results of sklearn.metrics:\")\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MSE:\", mse)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R-Squared:\", r2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOoj6ly0uHpR"
      },
      "source": [
        "## Fbprophet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MLMTZEiuLfL"
      },
      "source": [
        "  df_forcast = fb_prophet_prediction(france_data[\"confirmed\"])\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxJEoa674ueU"
      },
      "source": [
        "mae = metrics.mean_absolute_error(df_forcast[\"true\"], df_forcast[\"yhat\"])\n",
        "mse = metrics.mean_squared_error(df_forcast[\"true\"], df_forcast[\"yhat\"])\n",
        "rmse = np.sqrt(mse) # or mse**(0.5)  \n",
        "r2 = metrics.r2_score(df_forcast[\"true\"], df_forcast[\"yhat\"])\n",
        "\n",
        "print(\"Results of sklearn.metrics:\")\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MSE:\", mse)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R-Squared:\", r2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcO0lgn19I8x"
      },
      "source": [
        " ## Prediction for Deaths cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Bf-30n__spT"
      },
      "source": [
        "##LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFqbvpGu5IVK"
      },
      "source": [
        "df = train_eval_model_keras(norm=True, df=france_data[\"deaths\"], nb_epochs=30, batch_size=10)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9Q6jVd287Gi"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=df.index, y=df[\"y\"],\n",
        "                    mode='lines+markers',\n",
        "                    name='confirmed',marker_color='purple'))\n",
        "fig.add_trace(go.Scatter(x=df.index, y=df[\"yhat\"],\n",
        "                    mode='lines+markers',\n",
        "                    name='confirmed_prediction', marker_color='green'))\n",
        "\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Yg1_6EZCawI"
      },
      "source": [
        "#calcule mse , \n",
        "\n",
        "mae = metrics.mean_absolute_error(df[\"y\"], df[\"yhat\"])\n",
        "mse = metrics.mean_squared_error(df[\"y\"], df[\"yhat\"])\n",
        "rmse = np.sqrt(mse) # or mse**(0.5)  \n",
        "r2 = metrics.r2_score(df[\"y\"], df[\"yhat\"])\n",
        "\n",
        "print(\"Results of sklearn.metrics:\")\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MSE:\", mse)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R-Squared:\", r2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZDW3mcbCMVh"
      },
      "source": [
        "## Arima "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3r0nA8dCj0a"
      },
      "source": [
        "df_arima =get_prediction_using_ARIMA(france_data[\"deaths\"], \"deaths cases\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i02njAAyCuui"
      },
      "source": [
        "mae = metrics.mean_absolute_error(df_arima[\"y_true\"], df_arima[\"y_predicted\"])\n",
        "mse = metrics.mean_squared_error(df_arima[\"y_true\"], df_arima[\"y_predicted\"])\n",
        "rmse = np.sqrt(mse) # or mse**(0.5)  \n",
        "r2 = metrics.r2_score(df_arima[\"y_true\"], df_arima[\"y_predicted\"])\n",
        "\n",
        "print(\"Results of sklearn.metrics:\")\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MSE:\", mse)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R-Squared:\", r2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJdO0VBPCMlb"
      },
      "source": [
        "## fbprophet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGnaz4hECvBU"
      },
      "source": [
        "df_forcast = fb_prophet_prediction(france_data[\"deaths\"])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZDqf9cJC42c"
      },
      "source": [
        "mae = metrics.mean_absolute_error(df_forcast[\"true\"], df_forcast[\"yhat\"])\n",
        "mse = metrics.mean_squared_error(df_forcast[\"true\"], df_forcast[\"yhat\"])\n",
        "rmse = np.sqrt(mse) # or mse**(0.5)  \n",
        "r2 = metrics.r2_score(df_forcast[\"true\"], df_forcast[\"yhat\"])\n",
        "\n",
        "print(\"Results of sklearn.metrics:\")\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MSE:\", mse)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R-Squared:\", r2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIjwUJyh9NrE"
      },
      "source": [
        " ## Prediction for recovered cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4lkI402DW7U"
      },
      "source": [
        "##LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjuW7T1fDZNu"
      },
      "source": [
        "df = train_eval_model_keras(norm=True, df=france_data[\"recovered\"], nb_epochs=30, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQB46WrJCF5h"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=df.index, y=df[\"y\"],\n",
        "                    mode='lines+markers',\n",
        "                    name='confirmed',marker_color='purple'))\n",
        "fig.add_trace(go.Scatter(x=df.index, y=df[\"yhat\"],\n",
        "                    mode='lines+markers',\n",
        "                    name='confirmed_prediction', marker_color='green'))\n",
        "\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlJOeNI7CKnI"
      },
      "source": [
        "## ARIMA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xLoRWyN9QM0"
      },
      "source": [
        "df_arima =get_prediction_using_ARIMA(france_data[\"recovered\"], \"recovered cases\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCsZOQdqEVVs"
      },
      "source": [
        "mae = metrics.mean_absolute_error(df_arima[\"y_true\"], df_arima[\"y_predicted\"])\n",
        "mse = metrics.mean_squared_error(df_arima[\"y_true\"], df_arima[\"y_predicted\"])\n",
        "rmse = np.sqrt(mse) # or mse**(0.5)  \n",
        "r2 = metrics.r2_score(df_arima[\"y_true\"], df_arima[\"y_predicted\"])\n",
        "\n",
        "print(\"Results of sklearn.metrics:\")\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MSE:\", mse)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R-Squared:\", r2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt_hI_Y1DhG_"
      },
      "source": [
        "##Fbprophet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7m0m-QvDkQX"
      },
      "source": [
        "df_forcast = fb_prophet_prediction(france_data[\"recovered\"])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvw8pnw6EJFK"
      },
      "source": [
        "mae = metrics.mean_absolute_error(df_forcast[\"true\"], df_forcast[\"yhat\"])\n",
        "mse = metrics.mean_squared_error(df_forcast[\"true\"], df_forcast[\"yhat\"])\n",
        "rmse = np.sqrt(mse) # or mse**(0.5)  \n",
        "r2 = metrics.r2_score(df_forcast[\"true\"], df_forcast[\"yhat\"])\n",
        "\n",
        "print(\"Results of sklearn.metrics:\")\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MSE:\", mse)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R-Squared:\", r2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCes-HIRENWP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}